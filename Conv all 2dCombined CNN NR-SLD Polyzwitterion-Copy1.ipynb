{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fcec7e1-48c9-47ee-b2b3-9a83aeb3ab58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Neutron_Reflect' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!git clone https://github.com/miguel-fc/Neutron_Reflect.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "483dccd5-6554-4fef-937e-1ec0d64990d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/u1/q/qubri000/Neutron_Reflect\n"
     ]
    }
   ],
   "source": [
    "cd Neutron_Reflect/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f65f831-02c4-4394-8ecf-079fa84968be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pip in /global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages (23.3.1)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/pip/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e779cf8-dd4e-4bec-aa96-7a13d0e13827",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: gdown in /global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages (4.7.1)\n",
      "Requirement already satisfied: filelock in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from gdown) (3.0.12)\n",
      "Requirement already satisfied: requests[socks] in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from gdown) (2.26.0)\n",
      "Requirement already satisfied: six in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from gdown) (4.62.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages (from beautifulsoup4->gdown) (2.4.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from requests[socks]->gdown) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from requests[socks]->gdown) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from requests[socks]->gdown) (3.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c89da939-70ee-4038-b9f0-f5e872c004d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: seaborn in /global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages (from seaborn) (1.22.4)\n",
      "Requirement already satisfied: pandas>=0.25 in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from seaborn) (1.3.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from seaborn) (3.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (8.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from pandas>=0.25->seaborn) (2021.1)\n",
      "Requirement already satisfied: six in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from cycler>=0.10->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b02edc6-4f2f-4118-8ed3-eb5322b05ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: plotly in /global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages (5.16.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages (from plotly) (8.2.2)\n",
      "Requirement already satisfied: packaging in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from plotly) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from packaging->plotly) (2.4.7)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31100e48-c0ef-46af-b9cd-6c80108bfd44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: gdown in /global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages (4.7.1)\n",
      "Requirement already satisfied: filelock in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from gdown) (3.0.12)\n",
      "Requirement already satisfied: requests[socks] in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from gdown) (2.26.0)\n",
      "Requirement already satisfied: six in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from gdown) (4.62.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages (from beautifulsoup4->gdown) (2.4.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from requests[socks]->gdown) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from requests[socks]->gdown) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from requests[socks]->gdown) (3.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ay (/global/u1/q/qubri000/.local/perlmutter/pytorch1.9.0/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U --no-cache-dir gdown --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8a0de76-6079-4998-8a7d-7dba6fa661fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import data_preparation as dpre\n",
    "import io\n",
    "import os\n",
    "# import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "%matplotlib inline\n",
    "import seaborn as sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adadc327-ff32-48e9-bec4-3d9bdf9cbf87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_layers):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        addition = 255/num_layers\n",
    "        curr = 1\n",
    "        for hdim in range(num_layers-1):\n",
    "            self.layers.append(nn.Conv1d(int(curr+0.5), int(curr+addition+0.5),51,padding=25))\n",
    "            self.layers.append(nn.BatchNorm1d(int(curr+addition+0.5)))\n",
    "            self.layers.append(nn.ReLU(True))\n",
    "            curr += addition\n",
    "        self.layers.append(nn.Conv1d(int(curr+0.5), 256, 51, padding=25))\n",
    "        \n",
    "#         self.conv1 = nn.Conv1d(1,13,51,padding=25)\n",
    "#         self.batch1 = nn.BatchNorm1d(13)\n",
    "#         self.relu1 = nn.ReLU(True)\n",
    "        \n",
    "#         self.conv2 = nn.Conv1d(13,25,51,padding=25)\n",
    "#         self.batch2 = nn.BatchNorm1d(25)\n",
    "#         self.relu2 = nn.ReLU(True)\n",
    "        \n",
    "#         self.conv3 = nn.Conv1d(25,38,51,padding=25)\n",
    "#         self.batch3 = nn.BatchNorm1d(38)\n",
    "#         self.relu3 = nn.ReLU(True)\n",
    "        \n",
    "#         self.conv4 = nn.Conv1d(38,50,51,padding=25) \n",
    "#         self.batch4 = nn.BatchNorm1d(50)\n",
    "#         self.relu4 = nn.ReLU(True)\n",
    "        \n",
    "#         self.conv5 = nn.Conv1d(50,64,51,padding=25) \n",
    "#         self.batch5 = nn.BatchNorm1d(64)\n",
    "#         self.relu5 = nn.ReLU(True)\n",
    "        \n",
    "        self.linear1 = nn.Linear(256*308,900*2)\n",
    "        # self.linear2 = nn.Linear(120*308,2*308)\n",
    "        # self.linear2 = nn.Linear(33*308, 2*308)\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        # x = self.batch5(x)\n",
    "        # x = self.relu5(x)\n",
    "        # print(x.shape)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.linear1(x)\n",
    "        # x = self.linear2(x)\n",
    "        # x = self.linear2(x)\n",
    "        x = x.reshape(-1, 2, 900)\n",
    "        # print(x.shape)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "796dc609-1ba8-445d-aefe-9877c15cc452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Training function\n",
    "def fit(Model, device, dataloader, loss_fn, optim):\n",
    "    Model.train().to(device)\n",
    "    train_loss = []\n",
    "    for data,label in dataloader:\n",
    "        img = data\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        decoded_img = Model(img)\n",
    "        # print(decoded_img.shape)\n",
    "        # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "        loss = loss_fn(decoded_img, label)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        train_loss.append(loss.cpu().detach().numpy())\n",
    "        # print(label, \"hello\")\n",
    "    return np.mean(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "497a1381-dbbe-448e-98e7-176fa37ce09b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Valid function\n",
    "def val(Model, device, dataloader, loss_fn):\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad(): \n",
    "        list_decoded_img = []\n",
    "        list_img = []\n",
    "        for  data, label in dataloader:\n",
    "            img = data\n",
    "            # img = img.view(img.size(0), -1).to(device) \n",
    "            # img = img[:,np.newaxis,:].to(device) \n",
    "            img = img.to(device) \n",
    "            label = label.to(device)\n",
    "            decoded_img = Model(img)\n",
    "            # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "            list_decoded_img.append(decoded_img.cpu())\n",
    "            list_img.append(label.cpu())\n",
    "        list_decoded_img = torch.cat(list_decoded_img)\n",
    "        list_img = torch.cat(list_img)\n",
    "        # print(list_img, list_decoded_img, \"vaLLLLL FUNCTION\")\n",
    "#         for i in range(len(list_img)):\n",
    "            \n",
    "        val_loss = loss_fn(list_decoded_img, list_img)\n",
    "    return val_loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20bdb8db-de03-43a0-83d3-07cfba94c1b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_outputs(Model,dataset,device,n=10):\n",
    "  print(max_valX, min_valX)\n",
    "  plt.figure(figsize=(26,5.5))\n",
    "  for i in range(n):\n",
    "    ax = plt.subplot(2,n,i+1)\n",
    "    img, label =dataset[i]\n",
    "    img = img[:,np.newaxis,:].to(device) \n",
    "    #Notice that below i'm loading an image only, so it needs to be flatten\n",
    "    #before entering the network\n",
    "    # img = torch.flatten(img).to(device)\n",
    "    # print(label[0], \"hello\")\n",
    "    # print(img.shape)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(img)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "      # loss = loss_fn(decoded_img,label)\n",
    "      # print('For image {}, the loss = {}'.format(i,loss.data))\n",
    "    # print(label)\n",
    "    # print(label.shape)\n",
    "    plt.plot(label[0], label[1]) \n",
    "    if i == n//2:\n",
    "      ax.set_title('Original images')\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    plt.plot(decoded_img.cpu()[0][0], decoded_img.cpu()[0][1]) \n",
    "    if i == n//2:\n",
    "      ax.set_title('Reconstructed images')\n",
    "  plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca56a58-16d9-488f-8226-ed67bfda3373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n",
      "xtrain.shape, ytrain.shape, xval.shape, yval.shape, xtest.shape, ytest.shape\n",
      "(27000, 1, 308) (27000, 2, 900) (1500, 1, 308) (1500, 2, 900) (1500, 1, 308) (1500, 2, 900)\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "count = 0\n",
    "for first in range(5,6):\n",
    "    for second in range(5,6):\n",
    "        # print(first, second, count)\n",
    "        count += 1\n",
    "\n",
    "        # if count <=4:\n",
    "        #     continue\n",
    "        ### Define the loss function\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        lr= 2.15481e-05\n",
    "        torch.manual_seed(0)\n",
    "        Model = CNN(num_layers=12)\n",
    "        params_to_optimize = Model.parameters()\n",
    "\n",
    "        optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay= 2.6324e-05)\n",
    "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        Model.to(device)\n",
    "        print(first, second)\n",
    "        curves_nr = np.load('../NR-SLD_CurvesPoly' + str(first) + str(second) + '.npy')\n",
    "        curves_SLD = np.load('../SLD_CurvesPoly' + str(first) + str(second) + '.npy')\n",
    "        # for x in range(curves_nr.shape[0]):\n",
    "        #   plt.plot(curves_nr[x][0],curves_nr[x][1])\n",
    "        plt.xscale('log')\n",
    "        plt.yscale('log')\n",
    "\n",
    "        curves_nr = np.log10(curves_nr)\n",
    "\n",
    "        x_points = []\n",
    "        y_points = []\n",
    "        for curve in curves_nr:\n",
    "            x_points.append(curve[0])\n",
    "            y_points.append(curve[1])\n",
    "        min_valXNR = float('inf')\n",
    "        min_valYNR = float('inf')\n",
    "        max_valXNR = -float('inf')\n",
    "        max_valYNR = -float('inf')\n",
    "        for i in range(len(y_points)):\n",
    "            min_valXNR = min(min(x_points[i]), min_valXNR)\n",
    "            min_valYNR = min(min(y_points[i]), min_valYNR)\n",
    "            max_valXNR = max(max(x_points[i]), max_valXNR)\n",
    "            max_valYNR = max(max(y_points[i]), max_valYNR)\n",
    "        for i in range(len(y_points)):\n",
    "            for j in range(len(y_points[0])):\n",
    "                x_points[i][j] -= min_valXNR\n",
    "                y_points[i][j] -= min_valYNR\n",
    "                x_points[i][j] /= (max_valXNR - min_valXNR)\n",
    "                y_points[i][j] /= (max_valYNR - min_valYNR)\n",
    "        curves_nr2 = []\n",
    "        for i in range(len(y_points)):\n",
    "            curves_nr2.append([x_points[i],y_points[i]])\n",
    "        curves_nr2 = np.stack(curves_nr2)\n",
    "        curves_nr2.shape\n",
    "        # for x in range(curves_nr.shape[0]):\n",
    "        #   plt.plot(curves_nr[x][0],curves_nr[x][1])\n",
    "        # for x in range(curves_nr.shape[0]):\n",
    "        #   plt.plot(curves_SLD[x][0],curves_SLD[x][1])\n",
    "        x_points = []\n",
    "        y_points = []\n",
    "        for curve in curves_SLD:\n",
    "            x_points.append(curve[0].copy())\n",
    "            y_points.append(curve[1].copy())\n",
    "        min_valX = float('inf')\n",
    "        min_valY = float('inf')\n",
    "        max_valX = -float('inf')\n",
    "        max_valY= -float('inf')\n",
    "        for i in range(len(y_points)):\n",
    "            min_valX = min(min(x_points[i]), min_valX)\n",
    "            min_valY = min(min(y_points[i]), min_valY)\n",
    "            max_valX = max(max(x_points[i]), max_valX)\n",
    "            max_valY = max(max(y_points[i]), max_valY)\n",
    "        for i in range(len(y_points)):\n",
    "            for j in range(len(y_points[0])):\n",
    "                x_points[i][j] -= min_valX\n",
    "                y_points[i][j] -= min_valY\n",
    "                x_points[i][j] /= (max_valX - min_valX)\n",
    "                y_points[i][j] /= (max_valY - min_valY)\n",
    "        curves_SLD2 = []\n",
    "        for i in range(len(y_points)):\n",
    "            curves_SLD2.append([x_points[i],y_points[i]])\n",
    "        curves_SLD2 = np.stack(curves_SLD2)\n",
    "        curves_SLD2.shape\n",
    "        batch_size=32\n",
    "        R = curves_nr[:,1]\n",
    "\n",
    "        R_m = R[:,np.newaxis,:]\n",
    "        # Q = curves_SLD[:,1]\n",
    "        # Q_m = Q[:, np.newaxis,:]\n",
    "        xtrain, ytrain, xval, yval, xtest, ytest = \\\n",
    "        dpre.split_input_arrays(R_m,curves_SLD2, size_split=0.9)\n",
    "        #Prepare data files, continuation\n",
    "        train_dataset, valid_dataset, test_dataset, train_loader, valid_loader, test_loader = \\\n",
    "        dpre.get_dataloaders_fromsplitarrays(xtrain,ytrain,xval,yval,xtest,ytest,batch_size=batch_size)\n",
    "        num_epochs=500\n",
    "        #train and validate\n",
    "        diz_loss = {'train_loss':[],'val_loss':[]}\n",
    "        for epoch in range(num_epochs):\n",
    "          # if epoch % 10 ==0:\n",
    "          #   # Plot losses\n",
    "          #       plt.figure(figsize=(10,8))\n",
    "          #       plt.semilogy(diz_loss['train_loss'], label='Train')\n",
    "          #       plt.semilogy(diz_loss['val_loss'], label='Valid')\n",
    "          #       plt.xlabel('Epoch')\n",
    "          #       plt.ylabel('Average Loss')\n",
    "          #       plt.legend()\n",
    "          #       plt.show()\n",
    "\n",
    "          # print (epoch)\n",
    "            train_loss = fit(Model,device,train_loader,loss_fn,optim)\n",
    "            # print(train_loss)\n",
    "            val_loss = val(Model,device,valid_loader,loss_fn)\n",
    "            # print(val_loss)\n",
    "            diz_loss['train_loss'].append(train_loss)\n",
    "            diz_loss['val_loss'].append(val_loss)\n",
    "            # plot_outputs(Model,train_dataset,device,n=10)\n",
    "            \n",
    "        torch.save(Model.state_dict(), \"ModelPoly30000\" + str(first)+str(second))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac456c6-cc7b-410c-98d9-421ac89a44ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "gdown.download_folder(\"https://drive.google.com/drive/u/0/folders/10zAh8Dqr9c-vSflP35e6KFh54XdYQ-mr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c79f9a1-85b5-4e9d-95cb-0d165c4e2fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "directory = \"npoutputsPoly/\"\n",
    "totalDataPoly = []\n",
    "parametersPoly = []\n",
    "count = 0\n",
    "for i,filename in enumerate(os.listdir(directory)):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f):\n",
    "        print(f[14:])\n",
    "    currData = np.load(directory +f[14:])\n",
    "    xptPoly = []\n",
    "    yptPoly = []\n",
    "    parametersPoly.append([])\n",
    "    # print(f)\n",
    "    for j in range(10):\n",
    "        parametersPoly[count].append(int(f[26:32]))\n",
    "    for j in range(len(currData)):\n",
    "      xptPoly.append(currData[j][0])\n",
    "      yptPoly.append(currData[j][1])\n",
    "    np.array(xptPoly)\n",
    "    np.array(yptPoly)\n",
    "    # xpt2 = np.log10(xpt2)\n",
    "    # ypt2 = np.log10(ypt2)\n",
    "    totalDataPoly.append([xptPoly,yptPoly])\n",
    "    # print(xptPoly)\n",
    "    if i == 8:\n",
    "      print(f)\n",
    "    count += 1\n",
    "totalDataPoly = np.stack(totalDataPoly)\n",
    "for x in range(len(totalDataPoly)):\n",
    "  plt.plot(totalDataPoly[x][0],totalDataPoly[x][1])\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "# print(totalDataPoly)\n",
    "print(totalDataPoly.shape)\n",
    "totalDataPoly = np.log10(totalDataPoly)\n",
    "# for i in range(len(totalDataPoly)):\n",
    "#     newTestingData = []\n",
    "#     for j in range(len(totalDataPoly[i][0])):\n",
    "#       newTestingData.append([totalDataPoly[i][0][j], totalDataPoly[i][1][j]])\n",
    "#     for j in range(50):\n",
    "#       newTestingData.append([totalDataPoly[i][-1][0], totalDataPoly[i][-1][1]])\n",
    "#     newTestingData = np.stack(newTestingData)\n",
    "#     print(newTestingData.shape)\n",
    "#     window_size = 7\n",
    "#     smoothed_data = smooth_points(newTestingData, window_size)\n",
    "#     x_points = []\n",
    "#     y_points = []\n",
    "#     for j in range(len(newTestingData)):\n",
    "#         x_points\n",
    "#     totalDataPoly[i] = smoothed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d9b3d3-438e-428c-a4aa-fc621faca66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_pointsPoly = []\n",
    "y_pointsPoly = []\n",
    "for curve in totalDataPoly:\n",
    "    x_pointsPoly.append(curve[0])\n",
    "    y_pointsPoly.append(curve[1])\n",
    "# min_valXPoly = float('inf')\n",
    "# min_valYPoly = float('inf')\n",
    "# max_valXPoly = -float('inf')\n",
    "# max_valYPoly = -float('inf')\n",
    "# for i in range(len(y_pointsPoly)):\n",
    "#     min_valXPoly = min(min(x_pointsPoly[i]), min_valXPoly)\n",
    "#     min_valYPoly = min(min(y_pointsPoly[i]), min_valYPoly)\n",
    "#     max_valXPoly = max(max(x_pointsPoly[i]), max_valXPoly)\n",
    "#     max_valYPoly = max(max(y_pointsPoly[i]), max_valYPoly)\n",
    "for i in range(len(y_pointsPoly)):\n",
    "    for j in range(len(y_pointsPoly[0])):\n",
    "        x_pointsPoly[i][j] -= min_valXNR\n",
    "        y_pointsPoly[i][j] -= min_valYNR\n",
    "        x_pointsPoly[i][j] /= (max_valXNR - min_valXNR)\n",
    "        y_pointsPoly[i][j] /= (max_valYNR - min_valYNR)\n",
    "totalDataPoly2 = []\n",
    "for i in range(len(y_pointsPoly)):\n",
    "    totalDataPoly2.append([x_pointsPoly[i],y_pointsPoly[i]])\n",
    "totalDataPoly2 = np.stack(totalDataPoly2)\n",
    "totalDataPoly2.shape\n",
    "# for x in range(totalDataPoly.shape[0]):\n",
    "#   plt.plot(totalDataPoly[x][0],totalDataPoly[x][1])\n",
    "# for i in range(len(totalDataPoly)):\n",
    "#     diff = 1-totalDataPoly[i][1][0]\n",
    "#     print(diff)\n",
    "#     for j in range(len(totalDataPoly[0][0])):\n",
    "#         totalDataPoly[i][1][j] += diff\n",
    "for x in range(totalDataPoly.shape[0]):\n",
    "  plt.plot(totalDataPoly[x][0],totalDataPoly[x][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3b0f50-5a61-4a78-a59b-bc9a7f2ae14b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# totalDataPoly_log[:,0,:] = (totalDataPoly_log[:,0,:] - x_min)/(x_max - x_min)\n",
    "# totalDataPoly_log[:,1,:] = (totalDataPoly_log[:,1,:] - y_min)/(y_max - y_min)\n",
    "# for x in range(len(totalDataPoly_log)):\n",
    "#   plt.plot(totalDataPoly_log[x][0],totalDataPoly_log[x][1])\n",
    "# plt.show()\n",
    "totalDataPoly.shape\n",
    "RPoly = totalDataPoly[:,1]\n",
    "# parametersPoly = []\n",
    "# for i in range(21):\n",
    "#   parametersPoly.append([0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "parametersPoly = np.stack(parametersPoly)\n",
    "batch_size=64\n",
    "RPoly_m = RPoly[:,np.newaxis,:]\n",
    "xtrainPoly, ytrainPoly, xvalPoly, yvalPoly, xtestPoly, ytestPoly = \\\n",
    "dpre.split_input_arrays(RPoly_m,parametersPoly, size_split=0.9)\n",
    "#Prepare data files, continuation\n",
    "train_datasetPoly, valid_datasetPoly, test_datasetPoly, train_loaderPoly, valid_loaderPoly, test_loaderPoly = \\\n",
    "dpre.get_dataloaders_fromsplitarrays(xtrainPoly,ytrainPoly,xvalPoly,yvalPoly,xtestPoly,ytestPoly,batch_size=batch_size)\n",
    "print(train_datasetPoly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f20d7d-8b45-4c7a-9450-9d3ee24b2866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_outputs3(Model,dataset,device,loss_fn, n=10, ):\n",
    "  plt.figure(figsize=(26,5.5))\n",
    "  train_loss= []\n",
    "  print(max_valX, min_valX)\n",
    "  for i in range(n):\n",
    "    ax = plt.subplot(2,n,i+1)\n",
    "    img, label =dataset[i]\n",
    "    # label = label.to(device)\n",
    "    # label = label[:,np.newaxis,:].to(device) \n",
    "    img = img[:,np.newaxis,:].to(device) \n",
    "    #Notice that below i'm loading an image only, so it needs to be flatten\n",
    "    #before entering the network\n",
    "    # img = torch.flatten(img).to(device)\n",
    "    # print(label[0], \"hello\")\n",
    "    # print(img.shape)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(img)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "      # loss = loss_fn(decoded_img, label)\n",
    "      # train_loss.append(loss.cpu().detach().numpy())\n",
    "    # print(label)\n",
    "    # print(np.mean(train_loss))\n",
    "    print(int(label[0].item()))\n",
    "    plt.plot(img.cpu().numpy()[0][0])\n",
    "    # plt.xscale('log')\n",
    "    # plt.yscale('log')\n",
    "    if i == n//2:\n",
    "      ax.set_title('Neutron Reflectivity images')\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        \n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        \n",
    "        decoded_img[0][1][j] += min_valY\n",
    "        # x_points[i][j] /= (max_valX - min_valX)\n",
    "    plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1]) \n",
    "    if i == n//2:\n",
    "      ax.set_title('SLD images')\n",
    "  # print(np.mean(train_loss))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a378b-3ce0-4792-a501-18f5a4288225",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_outputs3(Model, train_datasetPoly, device, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8889c4-9dd7-46d1-8e02-25c2e45efcac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(test_datasetPoly)):\n",
    "    data, label = test_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    if label[0] == 202349:\n",
    "        plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        np.save(\"File 202349_2d\", decoded_img.cpu()[0])\n",
    "        with open('SLD202349_2d.txt', 'a') as f:\n",
    "            np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "    # if label[0] == 202272:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202272_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202272_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(train_datasetPoly)):\n",
    "    data, label = train_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    if label[0] == 202349:\n",
    "        plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        np.save(\"File 202349_2d\", decoded_img.cpu()[0])\n",
    "        with open('SLD202349_2d.txt', 'a') as f:\n",
    "            np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "    # if label[0] == 202272:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202272_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202272_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(valid_datasetPoly)):\n",
    "    data, label = valid_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    if label[0] == 202349:\n",
    "        plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        np.save(\"File 202349_2d\", decoded_img.cpu()[0])\n",
    "        with open('SLD202349_2d.txt', 'a') as f:\n",
    "            np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "\n",
    "    # if label[0] == 202272:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202272_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202272_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab792d27-c930-4ac5-bc7f-3f328af2b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(test_datasetPoly)):\n",
    "    data, label = test_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    if label[0] == 202293:\n",
    "        plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        np.save(\"File 202293_2d\", decoded_img.cpu()[0])\n",
    "        with open('SLD202293_2d.txt', 'a') as f:\n",
    "            np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "    # if label[0] == 202272:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202272_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202272_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(train_datasetPoly)):\n",
    "    data, label = train_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    if label[0] == 202293:\n",
    "        plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        np.save(\"File 202293_2d\", decoded_img.cpu()[0])\n",
    "        with open('SLD202293_2d.txt', 'a') as f:\n",
    "            np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "    # if label[0] == 202272:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202272_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202272_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(valid_datasetPoly)):\n",
    "    data, label = valid_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    if label[0] == 202293:\n",
    "        plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        np.save(\"File 202293_2d\", decoded_img.cpu()[0])\n",
    "        with open('SLD202293_2d.txt', 'a') as f:\n",
    "            np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "\n",
    "    # if label[0] == 202272:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202272_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202272_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c5f96-94d8-447b-bf11-71f2eef7e4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(test_datasetPoly)):\n",
    "    data, label = test_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    if label[0] == 202413:\n",
    "        plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        np.save(\"File 202413_2d\", decoded_img.cpu()[0])\n",
    "        with open('SLD202413_2d.txt', 'a') as f:\n",
    "            np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "    # if label[0] == 202272:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202272_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202272_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(train_datasetPoly)):\n",
    "    data, label = train_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    if label[0] == 202413:\n",
    "        plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        np.save(\"File 202413_2d\", decoded_img.cpu()[0])\n",
    "        with open('SLD202413_2d.txt', 'a') as f:\n",
    "            np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "    # if label[0] == 202272:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202272_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202272_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(valid_datasetPoly)):\n",
    "    data, label = valid_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    if label[0] == 202413:\n",
    "        plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        np.save(\"File 202413_2d\", decoded_img.cpu()[0])\n",
    "        with open('SLD202413_2d.txt', 'a') as f:\n",
    "            np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "\n",
    "    # if label[0] == 202272:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202272_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202272_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611cb525-23bc-4cc5-acb2-2f26ffff14f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(test_datasetPoly)):\n",
    "    data, label = test_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    if label[0] == 202307:\n",
    "        plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        np.save(\"File 202307_2d\", decoded_img.cpu()[0])\n",
    "        with open('SLD202307_2d.txt', 'a') as f:\n",
    "            np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "    # if label[0] == 202272:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202272_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202272_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(train_datasetPoly)):\n",
    "    data, label = train_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    if label[0] == 202307:\n",
    "        plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        np.save(\"File 202307_2d\", decoded_img.cpu()[0])\n",
    "        with open('SLD202307_2d.txt', 'a') as f:\n",
    "            np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "    # if label[0] == 202272:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202272_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202272_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(valid_datasetPoly)):\n",
    "    data, label = valid_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    if label[0] == 202307:\n",
    "        plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        np.save(\"File 202307_2d\", decoded_img.cpu()[0])\n",
    "        with open('SLD202307_2d.txt', 'a') as f:\n",
    "            np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "\n",
    "    # if label[0] == 202272:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202272_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202272_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3a814a-a374-48b8-90b2-b2cf5c759ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(test_datasetPoly)):\n",
    "    data, label = test_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    # if label[0] == 202349:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202349_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202349_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "    if label[0] == 202356:\n",
    "        plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        np.save(\"File 202356_2d\", decoded_img.cpu()[0])\n",
    "        with open('SLD202356_2d.txt', 'a') as f:\n",
    "            np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(train_datasetPoly)):\n",
    "    data, label = train_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    # if label[0] == 202349:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202349_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202349_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "    if label[0] == 202356:\n",
    "        plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        np.save(\"File 202356_2d\", decoded_img.cpu()[0])\n",
    "        with open('SLD202356_2d.txt', 'a') as f:\n",
    "            np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(valid_datasetPoly)):\n",
    "    data, label = valid_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    # if label[0] == 202349:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202349_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202349_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "    if label[0] == 202356:\n",
    "        plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        np.save(\"File 202356_2d\", decoded_img.cpu()[0])\n",
    "        with open('SLD202356_2d.txt', 'a') as f:\n",
    "            np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46aac26-3f9a-4bb2-9624-1e2f86e171f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model = torch.load(\"Model 7\")\n",
    "# print(Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec37d00a-1995-4123-9221-fc6eb6529089",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install refl1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b62ef-dffd-4061-9a33-e3a4753f4271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09705151-af4d-45d9-a8d6-5e22de946e00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.cla()\n",
    "import refl1d\n",
    "from refl1d.names import *\n",
    "\n",
    "def calculate_reflectivity_from_profile(q, z_step, sld, q_resolution=0.0294855):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "        Reflectivity calculation using refl1d from an array of microslabs\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # sld = np.flip(sld)\n",
    "    zeros = np.zeros(len(q))\n",
    "    dq = q_resolution * q / 2.355\n",
    "    # The QProbe object represents the beam\n",
    "\n",
    "    probe = QProbe(q, dq, data=(zeros, zeros))\n",
    "    sample = Slab(material=SLD(name='back', rho=sld[0], irho=0), interface=0)\n",
    "    # Add each layer\n",
    "    _prev_z = z_step[0]\n",
    "    for i, _sld in enumerate(sld):\n",
    "        if i>0:\n",
    "            thickness = z_step[i] - _prev_z\n",
    "            sample = sample | Slab(material=SLD(name='l_%d' % i, rho=_sld, irho=0),\n",
    "                                                thickness=thickness,\n",
    "                                                interface=0)\n",
    "        _prev_z = z_step[i]\n",
    "    probe.background = Parameter(value=0, name='background')\n",
    "    expt = Experiment(probe=probe, sample=sample)\n",
    "    a, r = expt.reflectivity()\n",
    "    return a, r\n",
    "z, sld = np.load(\"File 202356_2d.npy\")\n",
    "plt.plot(z, sld)\n",
    "plt.show()\n",
    "\n",
    "a, r = calculate_reflectivity_from_profile(np.logspace(np.log10(0.008101436040354381), np.log10(0.1975709062238298), num=308), z, sld)\n",
    "r = np.log10(r)\n",
    "np.save(\"File 202356_NR.npy\", [a,r])\n",
    "\n",
    "for i in range(len(r)):\n",
    "    # x_pointsPoly[i][j] -= min_valXNR\n",
    "    r[i] -= min_valYNR\n",
    "    # x_pointsPoly[i][j] /= (max_valXNR - min_valXNR)\n",
    "    r[i] /= (max_valYNR - min_valYNR)\n",
    "for i in range(len(train_datasetPoly)):\n",
    "    data, label = train_datasetPoly[i]\n",
    "    # print(label[0])\n",
    "    if label[0] == 202356:\n",
    "        # print(\"hi\")\n",
    "        # print(data[0])\n",
    "        # for j in range(len(r)):\n",
    "        #     r -= min_valYNR\n",
    "        #     r /= (max_valYNR - min_valYNR)\n",
    "        # print(\"hi\")\n",
    "        # print(data[0])\n",
    "        plt.plot(r)\n",
    "        plt.plot(data.cpu().numpy()[0])\n",
    "        # print(data)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "z2, sld2 = np.load(\"File 202437_2d.npy\")\n",
    "\n",
    "plt.plot(z2, sld2)\n",
    "plt.show()\n",
    "a2, r2 = calculate_reflectivity_from_profile(np.logspace(np.log10(0.008101436040354381), np.log10(0.1975709062238298), num=308), z2, sld2)\n",
    "np.save(\"File 202437_NR.npy\", [a2,r2])\n",
    "# plt.xscale('log')\n",
    "r2 = np.log10(r2)\n",
    "for i in range(len(r2)):\n",
    "    # x_pointsPoly[i][j] -= min_valXNR\n",
    "    r2[i] -= min_valYNR\n",
    "    # x_pointsPoly[i][j] /= (max_valXNR - min_valXNR)\n",
    "    r2[i] /= (max_valYNR - min_valYNR)\n",
    "for i in range(len(train_datasetPoly)):\n",
    "    data, label = train_datasetPoly[i]\n",
    "    # print(label[0])\n",
    "    if label[0] == 202437:\n",
    "        # print(\"hi\")\n",
    "        plt.plot(r2)\n",
    "        plt.plot(data.cpu().numpy()[0])\n",
    "plt.show()\n",
    "\n",
    "z3, sld3 = np.load(\"File 202349_2d.npy\")\n",
    "\n",
    "plt.plot(z3, sld3)\n",
    "plt.show()\n",
    "a3, r3 = calculate_reflectivity_from_profile(np.logspace(np.log10(0.008101436040354381), np.log10(0.1975709062238298), num=308), z3, sld3)\n",
    "np.save(\"File 202349_NR.npy\", [a3,r3])\n",
    "r3 = np.log10(r3)\n",
    "for i in range(len(r3)):\n",
    "    # x_pointsPoly[i][j] -= min_valXNR\n",
    "    r3[i] -= min_valYNR\n",
    "    # x_pointsPoly[i][j] /= (max_valXNR - min_valXNR)\n",
    "    r3[i] /= (max_valYNR - min_valYNR)\n",
    "for i in range(len(train_datasetPoly)):\n",
    "    data, label = train_datasetPoly[i]\n",
    "    # print(label[0])\n",
    "    if label[0] == 202349:\n",
    "        # print(\"hi\")\n",
    "        plt.plot(r3)\n",
    "        plt.plot(data.cpu().numpy()[0])\n",
    "plt.show()\n",
    "\n",
    "z4, sld4 = np.load(\"File 202413_2d.npy\")\n",
    "\n",
    "plt.plot(z4, sld4)\n",
    "plt.show()\n",
    "a4, r4 = calculate_reflectivity_from_profile(np.logspace(np.log10(0.008101436040354381), np.log10(0.1975709062238298), num=308), z4, sld4)\n",
    "np.save(\"File 202413_NR.npy\", [a4,r4])\n",
    "r4 = np.log10(r4)\n",
    "for i in range(len(r4)):\n",
    "    # x_pointsPoly[i][j] -= min_valXNR\n",
    "    r4[i] -= min_valYNR\n",
    "    # x_pointsPoly[i][j] /= (max_valXNR - min_valXNR)\n",
    "    r4[i] /= (max_valYNR - min_valYNR)\n",
    "for i in range(len(train_datasetPoly)):\n",
    "    data, label = train_datasetPoly[i]\n",
    "    # print(label[0])\n",
    "    if label[0] == 202413:\n",
    "        # print(\"hi\")\n",
    "        plt.plot(r4)\n",
    "        plt.plot(data.cpu().numpy()[0])\n",
    "plt.show()\n",
    "\n",
    "z5, sld5 = np.load(\"File 202307_2d.npy\")\n",
    "\n",
    "plt.plot(z5, sld5)\n",
    "plt.show()\n",
    "a5, r5 = calculate_reflectivity_from_profile(np.logspace(np.log10(0.008101436040354381), np.log10(0.1975709062238298), num=308), z5, sld5)\n",
    "np.save(\"File 202307_NR.npy\", [a5,r5])\n",
    "r5 = np.log10(r5)\n",
    "for i in range(len(r5)):\n",
    "    # x_pointsPoly[i][j] -= min_valXNR\n",
    "    r5[i] -= min_valYNR\n",
    "    # x_pointsPoly[i][j] /= (max_valXNR - min_valXNR)\n",
    "    r5[i] /= (max_valYNR - min_valYNR)\n",
    "for i in range(len(test_datasetPoly)):\n",
    "    data, label = test_datasetPoly[i]\n",
    "    # print(label[0])\n",
    "    if label[0] == 202307:\n",
    "        # print(\"hi\")\n",
    "        plt.plot(r5)\n",
    "        plt.plot(data.cpu().numpy()[0])\n",
    "plt.show()\n",
    "# z4, sld4 = np.load(\"File 202293_2d.npy\")\n",
    "\n",
    "# plt.plot(z4, sld4)\n",
    "# plt.show()\n",
    "# a4, r4 = calculate_reflectivity_from_profile(np.logspace(np.log10(0.008101436040354381), np.log10(0.1975709062238298), num=308), z4, sld4)\n",
    "# np.save(\"File 202293_NR.npy\", [a3,r3])\n",
    "# r4 = np.log10(r4)\n",
    "# for i in range(len(r4)):\n",
    "#     # x_pointsPoly[i][j] -= min_valXNR\n",
    "#     r4[i] -= min_valYNR\n",
    "#     # x_pointsPoly[i][j] /= (max_valXNR - min_valXNR)\n",
    "#     r4[i] /= (max_valYNR - min_valYNR)\n",
    "# for i in range(len(train_datasetPoly)):\n",
    "#     data, label = train_datasetPoly[i]\n",
    "#     # print(label[0])\n",
    "#     if label[0] == 202437:\n",
    "#         # print(\"hi\")\n",
    "#         plt.plot(r4)\n",
    "#         plt.plot(data.cpu().numpy()[0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feef12a4-91a9-41a8-b210-316e4eb60427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(test_datasetPoly)):\n",
    "    data, label = test_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    # if label[0] == 202349:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202349_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202349_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "    # if label[0] == 202356:\n",
    "    # print(decoded_img[0][0].cpu().numpy())\n",
    "    a, r = calculate_reflectivity_from_profile(np.logspace(np.log10(0.008101436040354381), np.log10(0.1975709062238298), num=308), decoded_img[0][0].cpu().numpy(), decoded_img[0][1].cpu().numpy())\n",
    "    r = np.log10(r)\n",
    "\n",
    "    for i in range(len(r)):\n",
    "        # x_pointsPoly[i][j] -= min_valXNR\n",
    "        r[i] -= min_valYNR\n",
    "        # x_pointsPoly[i][j] /= (max_valXNR - min_valXNR)\n",
    "        r[i] /= (max_valYNR - min_valYNR)\n",
    "        \n",
    "    print(int(label[0].item()))\n",
    "    plt.plot(data.cpu().numpy()[0][0])\n",
    "    plt.plot(r)\n",
    "    plt.show()\n",
    "    plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    plt.show()\n",
    "\n",
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(train_datasetPoly)):\n",
    "    data, label = train_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    a, r = calculate_reflectivity_from_profile(np.logspace(np.log10(0.008101436040354381), np.log10(0.1975709062238298), num=308), decoded_img[0][0].cpu().numpy(), decoded_img[0][1].cpu().numpy())\n",
    "    r = np.log10(r)\n",
    "\n",
    "    for i in range(len(r)):\n",
    "        # x_pointsPoly[i][j] -= min_valXNR\n",
    "        r[i] -= min_valYNR\n",
    "        # x_pointsPoly[i][j] /= (max_valXNR - min_valXNR)\n",
    "        r[i] /= (max_valYNR - min_valYNR)\n",
    "        \n",
    "    print(int(label[0].item()))\n",
    "    plt.plot(data.cpu().numpy()[0][0])\n",
    "    plt.plot(r)\n",
    "    plt.show()\n",
    "    plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    # np.save(\"File 202272_2d\", decoded_img.cpu()[0])\n",
    "    # with open('SLD202272_2d.txt', 'a') as f:\n",
    "    #     np.savetxt(f, decoded_img.cpu()[0])\n",
    "    plt.show()\n",
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(valid_datasetPoly)):\n",
    "    data, label = valid_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    a, r = calculate_reflectivity_from_profile(np.logspace(np.log10(0.008101436040354381), np.log10(0.1975709062238298), num=308), decoded_img[0][0].cpu().numpy(), decoded_img[0][1].cpu().numpy())\n",
    "    r = np.log10(r)\n",
    "\n",
    "    for i in range(len(r)):\n",
    "        # x_pointsPoly[i][j] -= min_valXNR\n",
    "        r[i] -= min_valYNR\n",
    "        # x_pointsPoly[i][j] /= (max_valXNR - min_valXNR)\n",
    "        r[i] /= (max_valYNR - min_valYNR)\n",
    "        \n",
    "    print(int(label[0].item()))\n",
    "    plt.plot(data.cpu().numpy()[0][0])\n",
    "    plt.plot(r)\n",
    "    plt.show()\n",
    "    plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    # np.save(\"File 202272_2d\", decoded_img.cpu()[0])\n",
    "    # with open('SLD202272_2d.txt', 'a') as f:\n",
    "    #     np.savetxt(f, decoded_img.cpu()[0])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbd6662-a09b-4f9d-9d7b-af89befc7d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(train_datasetPoly)):\n",
    "    data, label = train_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    # Model.eval().to(device)\n",
    "    # with torch.no_grad():\n",
    "    #   decoded_img  = Model(data)\n",
    "    #   # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    # for j in range(len(decoded_img[0][0])):\n",
    "    #     # x_points[i][j] -= min_valX\n",
    "    #     decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "    #     decoded_img[0][0][j] += min_valX\n",
    "    #     decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "    #     decoded_img[0][1][j] += min_valY\n",
    "    # if label[0] == 202349:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202349_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202349_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "    if label[0] == 202272:\n",
    "        # plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        # np.save(\"File 202272_2d\", decoded_img.cpu()[0])\n",
    "        # with open('SLD202272_2d.txt', 'a') as f:\n",
    "        #     np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "        file202272 = data.cpu().numpy()[0][0]\n",
    "        # print('hi')\n",
    "    if label[0] == 202356:\n",
    "        # plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        # np.save(\"File 202272_2d\", decoded_img.cpu()[0])\n",
    "        # with open('SLD202272_2d.txt', 'a') as f:\n",
    "        #     np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "        file202356 = data.cpu().numpy()[0][0]\n",
    "        # print('hi')\n",
    "    if label[0] == 202369:\n",
    "        # plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        # np.save(\"File 202272_2d\", decoded_img.cpu()[0])\n",
    "        # with open('SLD202272_2d.txt', 'a') as f:\n",
    "        #     np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "        file202369 = data.cpu().numpy()[0][0]\n",
    "        # print('hi')\n",
    "# print(file202272)\n",
    "# print(loss_fn(file202356, file202272))\n",
    "# print(torch.nn.MSELoss(file202356, file202272))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4772088-96f4-4275-99be-c4d1ff392564",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(test_datasetPoly)):\n",
    "    data, label = test_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    # if label[0] == 202349:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202349_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202349_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "    if label[0] == 202437:\n",
    "        plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        np.save(\"File 202437_2d\", decoded_img.cpu()[0])\n",
    "        with open('SLD202437_2d.txt', 'a') as f:\n",
    "            np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(train_datasetPoly)):\n",
    "    data, label = train_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    # if label[0] == 202349:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202349_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202349_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "    if label[0] == 202437:\n",
    "        plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        np.save(\"File 202437_2d\", decoded_img.cpu()[0])\n",
    "        with open('SLD202437_2d.txt', 'a') as f:\n",
    "            np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "#change test_datasetPoly to valid_datasetPoly or train_datasetPoly, depending on what dataset it is in\n",
    "for i in range(len(valid_datasetPoly)):\n",
    "    data, label = valid_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    # if label[0] == 202349:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202349_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202349_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "    if label[0] == 202293:\n",
    "        plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "        np.save(\"File 202437_2d\", decoded_img.cpu()[0])\n",
    "        with open('SLD202437_2d.txt', 'a') as f:\n",
    "            np.savetxt(f, decoded_img.cpu()[0])\n",
    "        plt.show()\n",
    "        plt.plot(data.cpu().numpy()[0][0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78934406-94e2-430e-8d50-519a0c23519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63671e20-c372-476b-9db3-162a5a93a445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(Model, \"Model 14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94f3445-340c-40d4-b902-d0b68b49a70c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92054988-30de-4896-81c5-01a4bb6cd5f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save(Model, \"Model 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c33a42-0b95-43e9-885e-d70fe855043a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save(Model, \"Model 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98e7cba-0796-4aa7-93e5-8834a4e1df80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save(Model, \"Model 7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac83497e-9e37-4559-8076-1786a7ddf175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save(Model, \"Model 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1418e4-3605-440e-9f55-13e63e11b6bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = torch.load(\"ML Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b776ec-2369-4905-bc01-40dbd27d0002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c939f60-2552-49fb-a07f-20d8dff7f8be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model = torch.load(\"Model 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd47d8-3758-496c-bc81-573b21e15edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(valid_datasetPoly)):\n",
    "    data, label = valid_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    # if label[0] == 202349:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202349_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202349_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "    # if label[0] == 202356:\n",
    "    # print(decoded_img[0][0].cpu().numpy())\n",
    "    a, r = calculate_reflectivity_from_profile(np.logspace(np.log10(0.008101436040354381), np.log10(0.1975709062238298), num=308), decoded_img[0][0].cpu().numpy(), decoded_img[0][1].cpu().numpy())\n",
    "    r = np.log10(r)\n",
    "\n",
    "    for i in range(len(r)):\n",
    "        # x_pointsPoly[i][j] -= min_valXNR\n",
    "        r[i] -= min_valYNR\n",
    "        # x_pointsPoly[i][j] /= (max_valXNR - min_valXNR)\n",
    "        r[i] /= (max_valYNR - min_valYNR)\n",
    "    # if label[0] == 202454:\n",
    "    plt.style.use(\"seaborn-darkgrid\")\n",
    "    plt.plot(decoded_img.cpu()[0][0], decoded_img.cpu()[0][1], linewidth=4, color=\"g\")\n",
    "    plt.xlabel(\"z []\")\n",
    "    plt.ylabel(\"SLD [$10^{-6}^{-2}$]\")\n",
    "    plt.title(\"Scattering Length Density Profile\")\n",
    "    plt.savefig(str(int(label[0].item())) + ' SLD Graph.jpeg')\n",
    "    plt.show()\n",
    "    a, r = calculate_reflectivity_from_profile(np.logspace(np.log10(0.008101436040354381), np.log10(0.1975709062238298), num=308), decoded_img.cpu()[0][0], decoded_img.cpu()[0][1])\n",
    "    other = np.load(\"../Neutron_Reflect/npoutputsPoly/np_out_REFL_\"+str(int(label[0].item()))+\"_combined_data_auto.npy\")\n",
    "    # # plt.plot(m.q,)\n",
    "    yPoints = []\n",
    "    xPoints = []\n",
    "    for i in range(len(other)):\n",
    "        xPoints.append(other[i][0])\n",
    "        yPoints.append(other[i][1])\n",
    "    plt.plot(a,r, linewidth=2, color='r', label=\"Reproduced NR curve from SLD profile\")\n",
    "    plt.scatter(xPoints, yPoints, linewidth=0.01, label=\"Original Experimental NR curve\")\n",
    "    # plt.xscale(\"log\")\n",
    "    plt.xlabel(\"q [1/]\")\n",
    "    plt.ylabel(\"r []\")\n",
    "    plt.title(\"Neutron Reflectivity\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    # print(data)\n",
    "    plt.savefig(str(int(label[0].item()))+' Neutron Reflectivity Graph.jpeg')\n",
    "    plt.show()\n",
    "\n",
    "for i in range(len(train_datasetPoly)):\n",
    "    data, label = train_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    # if label[0] == 202349:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202349_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202349_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "    # if label[0] == 202356:\n",
    "    # print(decoded_img[0][0].cpu().numpy())\n",
    "    a, r = calculate_reflectivity_from_profile(np.logspace(np.log10(0.008101436040354381), np.log10(0.1975709062238298), num=308), decoded_img[0][0].cpu().numpy(), decoded_img[0][1].cpu().numpy())\n",
    "    r = np.log10(r)\n",
    "\n",
    "    for i in range(len(r)):\n",
    "        # x_pointsPoly[i][j] -= min_valXNR\n",
    "        r[i] -= min_valYNR\n",
    "        # x_pointsPoly[i][j] /= (max_valXNR - min_valXNR)\n",
    "        r[i] /= (max_valYNR - min_valYNR)\n",
    "    # if label[0] == 202454:\n",
    "    plt.style.use(\"seaborn-darkgrid\")\n",
    "    plt.plot(decoded_img.cpu()[0][0], decoded_img.cpu()[0][1], linewidth=4, color=\"g\")\n",
    "    plt.xlabel(\"z []\")\n",
    "    plt.ylabel(\"SLD [$10^{-6}^{-2}$]\")\n",
    "    plt.title(\"Scattering Length Density Profile\")\n",
    "    plt.savefig(str(int(label[0].item()))+ ' SLD Graph.jpeg')\n",
    "    plt.show()\n",
    "    a, r = calculate_reflectivity_from_profile(np.logspace(np.log10(0.008101436040354381), np.log10(0.1975709062238298), num=308), decoded_img.cpu()[0][0], decoded_img.cpu()[0][1])\n",
    "    other = np.load(\"../Neutron_Reflect/npoutputsPoly/np_out_REFL_\"+str(int(label[0].item()))+\"_combined_data_auto.npy\")\n",
    "    # # plt.plot(m.q,)\n",
    "    yPoints = []\n",
    "    xPoints = []\n",
    "    for i in range(len(other)):\n",
    "        xPoints.append(other[i][0])\n",
    "        yPoints.append(other[i][1])\n",
    "    plt.plot(a,r, linewidth=2, color='r', label=\"Reproduced NR curve from SLD profile\")\n",
    "    plt.scatter(xPoints, yPoints, linewidth=0.01, label=\"Original Experimental NR curve\")\n",
    "    # plt.xscale(\"log\")\n",
    "    plt.xlabel(\"q [1/]\")\n",
    "    plt.ylabel(\"r []\")\n",
    "    plt.title(\"Neutron Reflectivity\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    # print(data)\n",
    "    plt.savefig(str(int(label[0].item()))+' Neutron Reflectivity Graph.jpeg')\n",
    "    plt.show()\n",
    "\n",
    "for i in range(len(test_datasetPoly)):\n",
    "    data, label = test_datasetPoly[i]\n",
    "    data = data[:,np.newaxis,:].to(device)\n",
    "    Model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "      decoded_img  = Model(data)\n",
    "      # decoded_img = decoded_img.reshape(-1,2, 308)\n",
    "    for j in range(len(decoded_img[0][0])):\n",
    "        # x_points[i][j] -= min_valX\n",
    "        decoded_img[0][0][j] *= (max_valX - min_valX)\n",
    "        decoded_img[0][0][j] += min_valX\n",
    "        decoded_img[0][1][j] *= (max_valY- min_valY)\n",
    "        decoded_img[0][1][j] += min_valY\n",
    "    # if label[0] == 202349:\n",
    "    #     plt.plot(decoded_img.cpu()[0][0],decoded_img.cpu()[0][1])\n",
    "    #     np.save(\"File 202349_2d\", decoded_img.cpu()[0])\n",
    "    #     with open('SLD202349_2d.txt', 'a') as f:\n",
    "    #         np.savetxt(f, decoded_img.cpu()[0])\n",
    "    # if label[0] == 202356:\n",
    "    # print(decoded_img[0][0].cpu().numpy())\n",
    "    a, r = calculate_reflectivity_from_profile(np.logspace(np.log10(0.008101436040354381), np.log10(0.1975709062238298), num=308), decoded_img[0][0].cpu().numpy(), decoded_img[0][1].cpu().numpy())\n",
    "    r = np.log10(r)\n",
    "\n",
    "    for i in range(len(r)):\n",
    "        # x_pointsPoly[i][j] -= min_valXNR\n",
    "        r[i] -= min_valYNR\n",
    "        # x_pointsPoly[i][j] /= (max_valXNR - min_valXNR)\n",
    "        r[i] /= (max_valYNR - min_valYNR)\n",
    "    # if label[0] == 202454:\n",
    "    plt.style.use(\"seaborn-darkgrid\")\n",
    "    plt.plot(decoded_img.cpu()[0][0], decoded_img.cpu()[0][1], linewidth=4, color=\"g\")\n",
    "    plt.xlabel(\"z []\")\n",
    "    plt.ylabel(\"SLD [$10^{-6}^{-2}$]\")\n",
    "    plt.title(\"Scattering Length Density Profile\")\n",
    "    plt.savefig(str(int(label[0].item())) + ' SLD Graph.jpeg')\n",
    "    plt.show()\n",
    "    a, r = calculate_reflectivity_from_profile(np.logspace(np.log10(0.008101436040354381), np.log10(0.1975709062238298), num=308), decoded_img.cpu()[0][0], decoded_img.cpu()[0][1])\n",
    "    other = np.load(\"../Neutron_Reflect/npoutputsPoly/np_out_REFL_\"+str(int(label[0].item()))+\"_combined_data_auto.npy\")\n",
    "    # # plt.plot(m.q,)\n",
    "    yPoints = []\n",
    "    xPoints = []\n",
    "    for i in range(len(other)):\n",
    "        xPoints.append(other[i][0])\n",
    "        yPoints.append(other[i][1])\n",
    "    plt.plot(a,r, linewidth=2, color='r', label=\"Reproduced NR curve from SLD profile\")\n",
    "    plt.scatter(xPoints, yPoints, linewidth=0.01, label=\"Original Experimental NR curve\")\n",
    "    # plt.xscale(\"log\")\n",
    "    plt.xlabel(\"q [1/]\")\n",
    "    plt.ylabel(\"r []\")\n",
    "    plt.title(\"Neutron Reflectivity\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    # print(data)\n",
    "    plt.savefig(str(int(label[0].item()))+' Neutron Reflectivity Graph.jpeg')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b4ad4e-df29-4ed1-9aac-307eb4442a09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b7e5e-8827-4e14-a102-3bd37c5aae12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.9.0",
   "language": "python",
   "name": "pytorch-1.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
